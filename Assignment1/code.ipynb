{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HathawayQAQ/COMP551-Machine-Learning/blob/main/Assignment1/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Statement"
      ],
      "metadata": {
        "id": "pLlL28Ne-Snh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TffOYnJa9Wjc",
        "outputId": "b69553ed-96c3-419d-9191-6a0b8cef7737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2.1.4)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.10/dist-packages (from ucimlrepo) (2024.8.30)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->ucimlrepo) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.16.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!pip install ucimlrepo\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task1: Acquire, preprocess, and analyze the data\n",
        "## Data Preperation\n",
        "1. Dataset1: Infrared Thermography Temperature (regression): [link](https://archive.ics.uci.edu/dataset/925/infrared+thermography+temperature+dataset)\n",
        "2. Dataset 2: CDC Diabetes Health Indicators (classification): [link](https://archive.ics.uci.edu/dataset/891/cdc+diabetes+health+indicators)"
      ],
      "metadata": {
        "id": "s0KxS7sd-W8z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data acquisition"
      ],
      "metadata": {
        "id": "Rkqf8vDnBL05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infrared_thermography_temperature = fetch_ucirepo(id=925)\n",
        "X = infrared_thermography_temperature.data.features\n",
        "y = infrared_thermography_temperature.data.targets"
      ],
      "metadata": {
        "id": "hllYmUX3-yJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "aYFifiVgAzLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "nan_rows = X.isnull().any(axis=1)\n",
        "X_clean = X[~nan_rows]\n",
        "y_clean = y[~nan_rows]\n",
        "\n",
        "# Handle categorical features\n",
        "categorical_columns = ['Age', 'Gender', 'Ethnicity']\n",
        "X_dummies = pd.get_dummies(X_clean, columns=categorical_columns, drop_first=True)\n",
        "\n",
        "# Convert boolean columns to integer\n",
        "bool_columns = X_dummies.select_dtypes(include=['bool']).columns\n",
        "for col in bool_columns:\n",
        "    X_dummies[col] = X_dummies[col].astype(int)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_dummies)\n",
        "\n",
        "# Select the target variable\n",
        "y_final = y_clean['aveOralM']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_final, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "w1VNh5In_lFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task2: Implement the Models"
      ],
      "metadata": {
        "id": "j25fBjIsF4hD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Linear Regression (Analytical Solution)"
      ],
      "metadata": {
        "id": "VhB-ZEXJF6la"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionModel:\n",
        "    def __init__(self):\n",
        "        self.weights = None\n",
        "\n",
        "    def fit(self, features, target):\n",
        "        num_samples, num_features = features.shape\n",
        "        features_with_bias = np.column_stack([np.ones(num_samples), features])  # Added bias term (ones)\n",
        "        self.weights, loss = self.calculate_least_squares_loss(features_with_bias, target)\n",
        "        return (loss, self.weights)\n",
        "\n",
        "    def calculate_least_squares_loss(self, features, target):\n",
        "        weights = np.linalg.inv(features.T @ features) @ features.T @ target\n",
        "        loss = np.mean((target - features @ weights) ** 2)\n",
        "        return weights, loss\n",
        "\n",
        "    def predict(self, features):\n",
        "        features_with_bias = np.column_stack([np.ones(features.shape[0]), features])  # Added bias term (ones)\n",
        "        return features_with_bias @ self.weights\n"
      ],
      "metadata": {
        "id": "aXd0ofrS_ZZr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearRegressionSGD:\n",
        "  def __init__(self):\n",
        "        self.weights = None\n",
        "  def fit(self, features, target, max_iterations=1000, tolerance=1e-5, learning_rate=1e-2, verbose=False, batch_size=16):\n",
        "        num_samples, num_features = features.shape\n",
        "        features_with_bias = np.column_stack([np.ones(num_samples), features])\n",
        "        target = target.astype(int)\n",
        "        rng = np.random.default_rng()\n",
        "\n",
        "        if self.weights is None:\n",
        "            self.weights = 0.001 * rng.standard_normal(num_features + 1)  # Random initialization\n",
        "\n",
        "        loss_history = []\n",
        "        for iteration in range(max_iterations):\n",
        "            batch_indices = rng.choice(np.arange(num_samples), batch_size, replace=False)\n",
        "            features_batch = features_with_bias[batch_indices, :]\n",
        "            target_batch = target[batch_indices]\n",
        "\n",
        "            gradient, loss = self.linear_loss(features_batch, target_batch)\n",
        "            loss_history.append(loss)\n",
        "\n",
        "            self.weights -= learning_rate * gradient  # Update weights\n",
        "\n",
        "            if verbose and iteration % 100 == 0:\n",
        "                print(f\"Iteration {iteration}: Loss {loss}\")\n",
        "\n",
        "        return loss_history\n",
        "\n",
        "  def predict(self, features):\n",
        "      features_with_bias = np.column_stack([np.ones(features.shape[0]), features])\n",
        "      return features_with_bias @ self.weights\n",
        "\n",
        "  def linear_loss(self, features, target):\n",
        "      num_samples = features.shape[0]\n",
        "      gradient = np.dot(features.T, np.dot(features, self.weights) - target) / num_samples\n",
        "      loss = np.sum((target - features @ self.weights) ** 2) / num_samples\n",
        "      return gradient, loss"
      ],
      "metadata": {
        "id": "wIexX-gpHlLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task3: Run Experiments\n"
      ],
      "metadata": {
        "id": "Mtuym_9RIQz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 1: Report performance of linear regression"
      ],
      "metadata": {
        "id": "etqK7v9WISe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LinearRegressionModel()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "test_r2 = r2_score(y_test, y_test_pred)\n",
        "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "\n",
        "print(\"Experiment 1: Linear Regression Performance\")\n",
        "print(f\"Training MSE: {train_mse:.4f}\")\n",
        "print(f\"Test MSE: {test_mse:.4f}\")\n",
        "print(f\"Training R-squared: {train_r2:.4f}\")\n",
        "print(f\"Test R-squared: {test_r2:.4f}\")\n",
        "print(f\"MAE (Train): {mae_train:.4f}\")\n",
        "print(f\"MAE (Test): {mae_test:.4f}\")"
      ],
      "metadata": {
        "id": "VdXGs5NJIWnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 2: Report weights of features"
      ],
      "metadata": {
        "id": "k3MXBM2mIYup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_dummies.columns,\n",
        "    'Coefficient': model.coefficients\n",
        "})\n",
        "feature_importance['Abs_Coefficient'] = abs(feature_importance['Coefficient'])\n",
        "feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nExperiment 2: Top 10 Feature Weights\")\n",
        "print(feature_importance.head(10))"
      ],
      "metadata": {
        "id": "zYJ2OiWhIcQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 3: Sample growing subsets of training data"
      ],
      "metadata": {
        "id": "6IK4LUW6IiCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sizes = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "train_scores = []\n",
        "test_scores = []\n",
        "\n",
        "for size in train_sizes:\n",
        "    x_train_subset, _, y_train_subset, _ = train_test_split(X_train, y_train, train_size=size, random_state=42)\n",
        "    model = LinearRegression()\n",
        "    model.fit(x_train_subset, y_train_subset)\n",
        "\n",
        "    train_pred = model.predict(x_train_subset)\n",
        "    test_pred = model.predict(X_test)\n",
        "\n",
        "    train_scores.append(r2_score(y_train_subset, train_pred))\n",
        "    test_scores.append(r2_score(y_test, test_pred))\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(train_sizes, train_scores, label='Train R-squared')\n",
        "plt.plot(train_sizes, test_scores, label='Test R-squared')\n",
        "plt.xlabel('Training Set Size')\n",
        "plt.ylabel('R-squared Score')\n",
        "plt.title('Learning Curve')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0UiSFoO5Ikd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 4: Try different mini-batch sizes"
      ],
      "metadata": {
        "id": "dL7rtc1rIrbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = [8, 16, 32, 64, 128]\n",
        "batch_scores = []\n",
        "\n",
        "def safe_r2_score(y_true, y_pred):\n",
        "    try:\n",
        "        return r2_score(y_true, y_pred)\n",
        "    except ValueError:\n",
        "        return float('-inf')\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    model = SGDLinearRegression(batch_size=batch_size)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = safe_r2_score(y_test, y_pred)\n",
        "    batch_scores.append(score)\n",
        "    print(f\"Batch size {batch_size}: Test R2= {score:.4f}\")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(batch_sizes, batch_scores, marker='o')\n",
        "plt.xlabel('Batch Size')\n",
        "plt.ylabel('Test R2 Score')\n",
        "plt.title('Effect of Batch Size on Model Performance')\n",
        "plt.xscale('log')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nExperiment 4: Mini-batch Size Performance\")\n",
        "for batch_size, score in zip(batch_sizes, batch_scores):\n",
        "    print(f\"Batch size {batch_size}: Test R2 = {score:.4f}\")"
      ],
      "metadata": {
        "id": "okTStqUgIuC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 5: Try different learning rates"
      ],
      "metadata": {
        "id": "wWHGCxb3IyTC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rates = [0.001, 0.01, 0.1]\n",
        "lr_scores = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    model = SGDLinearRegression(learning_rate=lr)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    score = safe_r2_score(y_test, y_pred)\n",
        "    lr_scores.append(score)\n",
        "    print(f\"Learning rate {lr}: Test R-squared = {score:.4f}\")\n",
        "\n",
        "print(\"\\nExperiment 5: Learning Rate Performance\")\n",
        "for lr, score in zip(learning_rates, lr_scores):\n",
        "    print(f\"Learning rate {lr}: Test R-squared = {score:.4f}\")"
      ],
      "metadata": {
        "id": "E8_fUTo6IzOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment 6: Compare analytical solution with mini-batch SGD"
      ],
      "metadata": {
        "id": "5jdmQXfRI2qR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "analytical_model = LinearRegression()\n",
        "analytical_model.fit(X_train, y_train)\n",
        "analytical_pred = analytical_model.predict(X_test)\n",
        "analytical_score = r2_score(y_test, analytical_pred)\n",
        "\n",
        "sgd_model = SGDLinearRegression()\n",
        "sgd_model.fit(X_train, y_train)\n",
        "sgd_pred = sgd_model.predict(X_test)\n",
        "sgd_score = r2_score(y_test, sgd_pred)\n",
        "\n",
        "print(\"\\nExperiment 6: Analytical vs SGD Performance\")\n",
        "print(f\"Analytical solution: Test R-squared = {analytical_score:.4f}\")\n",
        "print(f\"Mini-batch SGD: Test R-squared = {sgd_score:.4f}\")"
      ],
      "metadata": {
        "id": "RqiXySk6I3ax"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}